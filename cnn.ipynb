{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "from scipy import stats\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read classes\n",
    "classes = sorted(os.listdir(\"Data\"))\n",
    "\n",
    "# Initialize train and test data list\n",
    "train_images_path, test_images_path = [], []\n",
    "train_labels, test_labels = [], []\n",
    "\n",
    "# Set training data ratio\n",
    "train_ratio = 0.7\n",
    "\n",
    "for i, class_name in enumerate(classes):\n",
    "\n",
    "    # Read images in class folder\n",
    "    class_data = os.listdir(os.path.join(\"Data\", class_name))\n",
    "\n",
    "    # Train data are the first images\n",
    "    for img_name in class_data[:int(train_ratio*len(class_data))]: #0.7 primeres fotos\n",
    "        # Get only images paths\n",
    "        train_images_path.append(os.path.join(\"Data\", class_name, img_name))\n",
    "        # Append labels\n",
    "        train_labels.append(i)\n",
    "\n",
    "    # Test data are the last images\n",
    "    for img_name in class_data[int(train_ratio*len(class_data)):]:\n",
    "        # Get only images paths\n",
    "        test_images_path.append(os.path.join(\"Data\", class_name, img_name))\n",
    "        #Append labels\n",
    "        test_labels.append(i)\n",
    "\n",
    "\n",
    "train_images_path=np.array(train_images_path)\n",
    "test_images_path=np.array(test_images_path)\n",
    "train_labels = np.array(train_labels)\n",
    "test_labels=np.array(test_labels)\n",
    "\n",
    "#print(train_images_path,train_images_path.shape)\n",
    "#print(train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conv NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Image Shape: torch.Size([16, 3, 256, 256])\n",
      "Batch Label Shape: torch.Size([16, 4])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset as BaseDataset\n",
    "\n",
    "class Dataset(BaseDataset):\n",
    "\n",
    "    \"\"\"\n",
    "    Inherit from torch Dataset class. We overwrite _len_ and _getitem_ methods\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data, labels, num_classes):\n",
    "\n",
    "        # Call parent init\n",
    "        BaseDataset.__init__(self)\n",
    "\n",
    "        # Save raw data\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "\n",
    "        # Transform labels into one-hot encoding\n",
    "        self.hot_labels = torch.zeros(len(data), num_classes, dtype=float)\n",
    "        for idx, label in enumerate(labels):\n",
    "            self.hot_labels[idx, label] = 1\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        # Load image\n",
    "        img = np.array(Image.open(self.data[index]))\n",
    "        \n",
    "        torch_image = torch.from_numpy(img)\n",
    "\n",
    "        # Cast to float and normalize it\n",
    "        torch_image = torch_image.type(torch.float)/255 - 0.5\n",
    "\n",
    "\n",
    "        # Permute image into shape (channel, width, height)\n",
    "        torch_image = torch_image.permute((2, 0, 1))\n",
    "\n",
    "        return torch_image, self.hot_labels[index]\n",
    "\n",
    "train_dataset = Dataset(train_images_path, train_labels, len(classes))\n",
    "test_dataset = Dataset(test_images_path, test_labels, len(classes))\n",
    "\n",
    "    # Set batch-size, train_loader and test_loader\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "# Iterate through the DataLoader\n",
    "for images, labels in train_loader:\n",
    "    # Debug: Print batch shape and type\n",
    "    print(f\"Batch Image Shape: {images.shape}\")\n",
    "    print(f\"Batch Label Shape: {labels.shape}\")\n",
    "    break  \n",
    "\n",
    "# print(\"Train image paths\", len(train_images_path))\n",
    "# print(\"Test image paths\", len(test_images_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class ConvNet(nn.Module):\n",
    "\n",
    "    \"\"\"\n",
    "    Set custom small convolutional nn.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_size, num_classes):\n",
    "\n",
    "        # Call parent's init\n",
    "        super(ConvNet, self).__init__()\n",
    "\n",
    "        # Define backbone\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(input_size, 500, (5, 5)),\n",
    "            nn.MaxPool2d(3),\n",
    "            nn.Conv2d(500, 250, (3, 3)),\n",
    "            nn.MaxPool2d(3),\n",
    "            nn.Conv2d(250, 100, (7, 7)),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(100, 250, (5, 5)),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(250, 100, (3, 3)),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(100, 10, (3, 3)),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "\n",
    "        # Set classification layer\n",
    "        self.fc = nn.Linear(1690, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        batch_size = x.shape[0]\n",
    "\n",
    "        # Apply backbone\n",
    "        y = self.conv_layers(x)\n",
    "\n",
    "        # Apply classification layer\n",
    "        y = y.view(batch_size, -1)\n",
    "        return self.fc(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classes ['glioma_tumor', 'meningioma_tumor', 'normal', 'pituitary_tumor']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 931/931 [11:10<00:00,  1.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Accuracy: 81.7401 %\n",
      "Confusion matrix [[222  35  10   4]\n",
      " [ 41 204   5  24]\n",
      " [  5  13 109   5]\n",
      " [  7  19   2 226]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [931, 1]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 86\u001b[0m\n\u001b[0;32m     82\u001b[0m c_matrix \u001b[38;5;241m=\u001b[39m confusion_matrix(ground_truth, predictions)\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConfusion matrix\u001b[39m\u001b[38;5;124m\"\u001b[39m, c_matrix)\n\u001b[1;32m---> 86\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy =\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43maccuracy_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43mpredicted\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrecision =\u001b[39m\u001b[38;5;124m\"\u001b[39m, precision_score(test_labels,predicted,average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmacro\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m     88\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRecall =\u001b[39m\u001b[38;5;124m\"\u001b[39m, recall_score(test_labels,predicted,average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmacro\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\evida\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\evida\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\metrics\\_classification.py:213\u001b[0m, in \u001b[0;36maccuracy_score\u001b[1;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Accuracy classification score.\u001b[39;00m\n\u001b[0;32m    148\u001b[0m \n\u001b[0;32m    149\u001b[0m \u001b[38;5;124;03mIn multilabel classification, this function computes subset accuracy:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    209\u001b[0m \u001b[38;5;124;03m0.5\u001b[39;00m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    212\u001b[0m \u001b[38;5;66;03m# Compute accuracy for each possible representation\u001b[39;00m\n\u001b[1;32m--> 213\u001b[0m y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    214\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\evida\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\metrics\\_classification.py:85\u001b[0m, in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_targets\u001b[39m(y_true, y_pred):\n\u001b[0;32m     59\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Check that y_true and y_pred belong to the same classification task.\u001b[39;00m\n\u001b[0;32m     60\u001b[0m \n\u001b[0;32m     61\u001b[0m \u001b[38;5;124;03m    This converts multiclass or binary types to a common shape, and raises a\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;124;03m    y_pred : array or indicator matrix\u001b[39;00m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 85\u001b[0m     \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     86\u001b[0m     type_true \u001b[38;5;241m=\u001b[39m type_of_target(y_true, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     87\u001b[0m     type_pred \u001b[38;5;241m=\u001b[39m type_of_target(y_pred, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_pred\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\evida\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\utils\\validation.py:457\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    455\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[0;32m    456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 457\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    458\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    459\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[0;32m    460\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [931, 1]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "device = \"cpu\" #\"cuda\" on colab\n",
    "print(\"classes\", classes)\n",
    "\n",
    "TRAIN = False\n",
    "if TRAIN:\n",
    "\n",
    "    # Num epochs\n",
    "    num_epochs = 25\n",
    "\n",
    "    # Initialie model class with random weights\n",
    "    model = ConvNet(3, len(classes)).to(device)\n",
    "\n",
    "    # Set loss function, optimizer and learning-rate scheduler\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, num_epochs)\n",
    "\n",
    "    # Set initialize validation score\n",
    "    valid_score = 0\n",
    "\n",
    "    # Train the model\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "\n",
    "        print(\"Epoch: [\", epoch + 1, \"/\", num_epochs, \"] | learning rate\", scheduler.get_lr())\n",
    "\n",
    "        for images, labels in tqdm(train_loader):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # print(\"epoch\", epoch, \"loss\", loss.item(), end=\"\\r\")\n",
    "        scheduler.step()\n",
    "\n",
    "        # Test the model\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for images, labels in tqdm(test_loader):\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "                outputs = model(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == torch.max(labels, 1)[1]).sum().item()\n",
    "            print('Test Accuracy: %.4f %%' % (100 * correct / total))\n",
    "        if correct/total > valid_score:\n",
    "            print(\"saving model...\")\n",
    "            torch.save(model, \"drive/MyDrive/emma_erasmus/model.pt\")\n",
    "            valid_score = correct/total\n",
    "else:\n",
    "    model = torch.load(\"model1.pt\", map_location=device)\n",
    "    # Test the model\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    predictions = []\n",
    "    ground_truth = []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(test_loader):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "\n",
    "            predicted_ = predicted.cpu().item()\n",
    "            label_ = torch.max(labels, 1)[1].cpu().item()\n",
    "\n",
    "            predictions.append(predicted_)\n",
    "            ground_truth.append(label_)\n",
    "\n",
    "            correct += predicted_ == label_\n",
    "        print('\\nTest Accuracy: %.4f %%' % (100 * correct / total))\n",
    "\n",
    "    # Confusion matrix\n",
    "    c_matrix = confusion_matrix(ground_truth, predictions)\n",
    "    print(\"Confusion matrix\", c_matrix)\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.8174006444683136\n",
      "Precision = 0.8244266231535604\n",
      "Recall = 0.8198087736530772\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy =\", accuracy_score(ground_truth,predictions))\n",
    "print(\"Precision =\", precision_score(ground_truth,predictions,average='macro'))\n",
    "print(\"Recall =\", recall_score(ground_truth,predictions,average='macro'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
